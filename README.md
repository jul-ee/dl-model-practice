# 📝 TensorFlow 기반 딥러닝 모델 실습

이 repository는 TensorFlow와 Keras를 활용한 딥러닝 실습 노트북을 정리한 공간입니다.

다양한 데이터셋으로 모델 훈련, 저장, 정규화, 초기화, 옵티마이저 실험 등을 수행하였습니다. 딥러닝 이론 학습을 기반으로 실습으로 확장하였고, 각 노트북은 독립적인 실습 단위로 구성되어 있습니다.

<br>


## 폴더 구조 및 실습 개요

```
📁 dl_model_practice/
│
├── 01_rock_paper_scissor.ipynb                # 가위바위보 이미지 분류 모델 실습
├── 02_model_save_callback.ipynb               # 모델 저장 및 콜백 함수 실습
├── 03_model_train_skill.ipynb                 # 모델 학습 기술 (조기 종료, 모델 평가) 실습
├── 04_model_regularization.ipynb              # 과적합 방지를 위한 정규화 기법 실습
├── 05_weights_initialization_batch_normalization.ipynb  # 가중치 초기화 & 배치 정규화 실습
├── 06_fashion_mnist_practice.ipynb            # 패션 MNIST 데이터셋 분류 실습
└── 07_deep_learning_projects.ipynb            # 종합 딥러닝 프로젝트 실습 모음

```

<br>
<br>

## 실습 주요 내용

### 01. `01_rock_paper_scissor.ipynb`

#### 1) MNIST 손글씨 숫자 분류

- 데이터: MNIST 숫자 이미지 (28×28, 10클래스)
- 목표: 기본 MLP 신경망을 활용한 숫자 분류
- 학습 흐름
    1. MNIST 데이터 로드 및 정규화
    2. Dense 레이어 기반 MLP 모델 구성
    3. 학습 및 검증 정확도 시각화
- 주요 실습 내용
    - Flatten → Dense → Softmax 구조
    - 손실 및 정확도 추이 시각화
- 인사이트 및 회고
    - 기본 구조를 직접 구현하며 분류 모델의 동작 원리를 익힘

#### 2) 가위바위보 이미지 분류

- 데이터: 사용자 수집 RGB 이미지 (가위, 바위, 보)
- 목표: 커스텀 이미지 데이터로 다중 분류 모델 구현
- 학습 흐름:
    1. 이미지 리사이즈 및 정규화
    2. 라벨링 및 데이터 로딩
    3. Dense 기반 모델 구성 및 예측
- 주요 실습 내용
    - RGB 이미지 전처리 및 라벨 매핑
    - 실제 이미지 데이터를 통한 모델 학습 및 테스트
- 인사이트 및 회고
    - 딥러닝을 현실 문제에 적용하는 첫 경험으로 매우 유의미했음.

<br>

### 02. `02_model_save_callback.ipynb`

- 데이터: MNIST 숫자 이미지
- 목표: 콜백 함수로 모델 자동 저장 및 과적합 방지
- 학습 흐름
    1. 학습/검증 분할
    2. `ModelCheckpoint`, `EarlyStopping` 설정
    3. 학습 곡선 시각화
- 주요 실습 내용
    - 최적 모델 `.h5` 파일로 저장
    - 조기 종료로 불필요한 epoch 방지
- 인사이트 및 회고
    - 이전 프로젝트에서 구성했던 모델에 콜백을 적용하여 최적화시키는 방법을 이해함

<br>

### 03. `03_model_train_skill.ipynb`

- 데이터: IMDB 영화 리뷰 (정수 인덱스 기반, 2클래스)
- 목표: 텍스트 데이터를 위한 분류 모델 구성 및 과적합 분석
- 학습 흐름
    1. 정수 시퀀스 정규화
    2. MLP 모델 구성 및 학습
    3. 검증 손실 시각화
- 주요 실습 내용
    - Embedding 없이 정수 시퀀스 직접 학습
    - history 객체로 학습 추이 분석
- 인사이트 및 회고
    - 간단한 모델에서도 과적합이 발생할 수 있고, 이를 판단하는 시각화가 중요하다는 것을 확인함

<br>

### 04. `04_model_regularization.ipynb`

- 데이터: IMDB 리뷰 (원-핫 인코딩)
- 목표: 정규화 기법(L2, Dropout)을 적용해 과적합 해결
- 학습 흐름
    1. 작은 모델/큰 모델 성능 비교
    2. `L2`, `Dropout` 적용 및 효과 확인
- 주요 실습 내용
    - 과적합 패턴 시각화
    - 정규화 후 손실 감소 확인
- 인사이트 및 회고
    - 딥러닝 모델에서는 구조 변경이 일반화 성능을 크게 개선할 수 있다는 점을 확인함

<br>

### 05. `05_weights_initialization_batch_normalization.ipynb`

- 데이터: 무작위 벡터 입력 (400×20 차원)
- 목표: 가중치 초기화 및 배치 정규화가 출력 분포에 미치는 영향 분석
- 학습 흐름
    1. 다양한 초기화 방식 (He, Xavier) 적용
    2. BatchNorm 유무 비교
    3. 히스토그램 시각화
- 주요 실습 내용
    - MLP 은닉층 출력값 시각화
    - 배치 정규화 위치에 따른 성능 변화 실험
- 인사이트 및 회고
    - 딥러닝 모델의 학습 안정성을 위해 초기화와 정규화의 중요성을 확인함

<br>

### 06. `06_fashion_mnist_practice.ipynb`

- 데이터: Fashion MNIST (10개 클래스, 흑백 이미지)
- 목표: CNN 없이 MLP 기반 분류 모델 구성
- 학습 흐름
    1. 데이터 로딩 및 정규화
    2. Dense 기반 분류 모델 구성
    3. 오차 행렬 및 분류 리포트 출력
- 주요 실습 내용
    - Flatten → Dense → Softmax 구조
    - 성능 분석을 통한 한계 인식
- 인사이트 및 회고
    - CNN 없이 baseline 모델로서 성능이 어떻게 확보될 수 있을지 확인함

<br>

### 07. `07_deep_learning_projects.ipynb`

#### 1) Boston Housing – 회귀 예측

- 데이터: 보스턴 주택 가격 (13개 특성)
- 목표: MLP 모델로 주택 가격을 연속 예측
- 학습 흐름
    1. 정규화 → Dense 모델 구성
    2. MSE/MAE 평가
    3. 예측 결과 시각화
- 주요 실습 내용
    - 회귀 문제에서의 손실 정의와 시각화
- 인사이트 및 회고
    - 정답이 범주가 아닌 수치일 때 모델 구성 방식이 어떻게 달라지는지 확인함


#### 2) Reuters – 뉴스 다중 분류

- 데이터: 로이터 기사 (46개 주제)
- 목표: 텍스트 다중 클래스 분류 모델 구성
- 학습 흐름
    1. 정수 인코딩 및 one-hot 라벨 처리
    2. Embedding → Dense 구조 학습
    3. 조기 종료 및 정확도 평가
- 주요 실습 내용
    - 희소 벡터 기반 분류
    - EarlyStopping 적용
- 인사이트 및 회고
    - 다중 분류 문제에서의 모델 구성, 손실함수, 평가 지표를 실습해볼 수 있었음

#### 3) CIFAR-10 – 옵티마이저에 따른 EarlyStopping 반응 비교 실험

- 데이터: CIFAR-10 컬러 이미지 (32×32, 10개 클래스)
- 목표: CNN 없이 Dense 모델로 이미지 분류를 시도하며, 옵티마이저에 따라 EarlyStopping이 어떻게 작동하는지 비교
- 학습 흐름
    1. 이미지 정규화 및 Dense 모델 구성
    2. 두 가지 옵티마이저(Adam, SGD)를 사용하여 각각 모델 학습
    3. 동일한 조건에서 `EarlyStopping` 및 `ModelCheckpoint` 콜백 적용
    4. validation loss 모니터링을 통해 학습 조기 종료 여부 확인
- 주요 실습 내용
    - Adam 사용 시 조기 종료가 빠르게 일어나는 반면, SGD는 손실 감소가 더디기 때문에 종료 트리거가 잘 작동하지 않는 현상 관찰
    - 학습 곡선 및 조기 종료 조건의 옵티마이저 의존성 분석
- 인사이트 및 회고
    - EarlyStopping은 항상 작동하지만, 옵티마이저의 손실 수렴 특성에 따라 눈에 띄는 차이를 보인다는 사실을 실험으로 검증
    - 옵티마이저 선택이 모델 성능은 물론 학습 전략에도 영향을 준다는 점을 이해함

<br>

>이 repository는 딥러닝 이론에서 실제 모델 구성으로 확장해나가기 위한 기초를 다지는 데 중점을 두었습니다.
